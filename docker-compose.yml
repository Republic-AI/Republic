version: "3.8"
services:
  python-llm-service:
    build: ./python-llm-service
    container_name: python-llm-service
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    ports:
      - "5001:5001"
    image: mirror.gcr.io/library/python:3.9-slim

  node-llm-service:
    build: ./node-llm-service
    container_name: node-llm-service
    environment:
      - OPENAI_API_KEY=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
      - TWITTER_RAPIDAPI_KEY=${TWITTER_RAPIDAPI_KEY}
    ports:
      - "5002:5002"
    image: mirror.gcr.io/library/node:18-alpine

  orchestrator:
    build: ./orchestrator
    container_name: orchestrator
    depends_on:
      - python-llm-service
      - node-llm-service
    ports:
      - "8080:8080"

  frontend:
    build: ./frontend
    container_name: frontend
    depends_on:
      - orchestrator
    ports:
      - "3000:80"